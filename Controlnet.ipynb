{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RisHgyMLv1Fk"
      },
      "outputs": [],
      "source": [
        "!pip install controlnet_aux\n",
        "!pip install diffusers transformers accelerate"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import os\n",
        "from huggingface_hub import HfApi\n",
        "from pathlib import Path\n",
        "from diffusers.utils import load_image\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "from controlnet_aux import OpenposeDetector\n",
        "\n",
        "from diffusers import (\n",
        "    ControlNetModel,\n",
        "    StableDiffusionControlNetPipeline,\n",
        "    UniPCMultistepScheduler,\n",
        ")\n",
        "\n",
        "checkpoint = \"lllyasviel/control_v11p_sd15_openpose\"\n"
      ],
      "metadata": {
        "id": "iuN4AMJQwE4t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image = load_image(\"\") ##load original\n",
        "\n",
        "processor = OpenposeDetector.from_pretrained('lllyasviel/ControlNet')\n",
        "\n",
        "control_image = processor(image, hand_and_face=True)\n",
        "control_image.save(\"/content/control.png\")\n"
      ],
      "metadata": {
        "id": "FZTCnSTizg80"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Image\n",
        "image_path = '/content/control.png'\n",
        "Image(filename=image_path)"
      ],
      "metadata": {
        "id": "uHrQlgM6ymXy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "controlnet = ControlNetModel.from_pretrained(checkpoint, torch_dtype=torch.float16)\n",
        "\n",
        "pipe = StableDiffusionControlNetPipeline.from_pretrained(\n",
        "    \"runwayml/stable-diffusion-v1-5\", controlnet=controlnet, torch_dtype=torch.float16\n",
        ")\n",
        "\n",
        "pipe.scheduler = UniPCMultistepScheduler.from_config(pipe.scheduler.config)\n",
        "pipe.enable_model_cpu_offload()\n",
        "generator = torch.manual_seed(0)\n"
      ],
      "metadata": {
        "id": "X49hw9jyxzwv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"\" ##prompt here\n",
        "quality = 10 #num\n",
        "image = pipe(prompt, num_inference_steps=quality, generator=generator, image=control_image).images[0]\n",
        "image.save('/content/image_out.png')"
      ],
      "metadata": {
        "id": "jDAUaRwH4qWo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#show output\n",
        "from IPython.display import Image\n",
        "\n",
        "image_path = '/content/SAM_2264.png'\n",
        "\n",
        "Image(filename=image_path)\n"
      ],
      "metadata": {
        "id": "svIbSPfkxYyz"
      },
      "execution_count": 9,
      "outputs": []
    }
  ]
}